{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW8_AutoML & Vision API.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "ggjuE4es7SDH",
        "YCFS4tqcLW8S",
        "QYU7DysIifKH",
        "uBi7uKYCL6JM",
        "tho4WI7ikZb0",
        "hPWO_zyRopXN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chloe0704/GCP_AutoML_Vision/blob/master/AutoML_%26_Vision_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dRxWhH0g3tKF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hw8: Flower classification with AutoML\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ggjuE4es7SDH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GCP AutoML\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ydR9SXDKAXvk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![GCP AutoML](https://user-images.githubusercontent.com/58792/45260264-134c4800-b397-11e8-9832-fd56a8eeaa3c.png)\n",
        "\n",
        "\n",
        "**[GCP AutoML Products](https://cloud.google.com/automl/)**\n",
        "\n",
        "*  [AutoML Vision](https://cloud.google.com/vision/automl/docs/)\n",
        "*  [AutoML Natural Language](https://cloud.google.com/natural-language/automl/docs/)\n",
        "*  [AutoML Translation](https://cloud.google.com/translate/automl/docs/)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YCFS4tqcLW8S"
      },
      "cell_type": "markdown",
      "source": [
        "### Data Ingestion\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "pmGu051mLW8V"
      },
      "cell_type": "markdown",
      "source": [
        "####Load dataset\n",
        "\n",
        "![GCP AutoML data](https://raw.githubusercontent.com/Chloe0704/Images/master/AutoML_dataset.png)\n",
        "\n",
        "\n",
        "###Check the availability\n",
        "![GCP AutoML dataset](https://raw.githubusercontent.com/Chloe0704/Images/master/AutoML_dataview.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "QYU7DysIifKH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### GCP AutoML Model\n"
      ]
    },
    {
      "metadata": {
        "id": "MAtZVZgRin7e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "![GCP Model](https://raw.githubusercontent.com/Chloe0704/Images/master/AutoML_model.png)\n",
        "\n",
        "\n",
        "![GCP Model_eval](https://raw.githubusercontent.com/Chloe0704/Images/master/AutoML_eval.png)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uBi7uKYCL6JM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Prediciton"
      ]
    },
    {
      "metadata": {
        "id": "gljcIbNoL91o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![pred_sun](https://raw.githubusercontent.com/Chloe0704/Images/master/pred_sun.png)\n",
        "\n",
        "\n",
        "![pred_sun](https://raw.githubusercontent.com/Chloe0704/Images/master/pred_d.png)\n"
      ]
    },
    {
      "metadata": {
        "id": "tho4WI7ikZb0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## GCP Vision API"
      ]
    },
    {
      "metadata": {
        "id": "desIuhDTkogY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://cloud.google.com/vision/\n",
        "\n",
        "![Vision API](https://cloud.google.com/images/products/vision/image-search.svg)\n",
        "\n",
        "* [Step 1:  Enable API](https://cloud.google.com/vision/docs/before-you-begin)"
      ]
    },
    {
      "metadata": {
        "id": "hPWO_zyRopXN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Mount Drive\n"
      ]
    },
    {
      "metadata": {
        "id": "XI73HZNLobp4",
        "colab_type": "code",
        "outputId": "539e3cf2-dad8-409c-d0d7-608bf7933f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UNyzZwgmoxwm",
        "colab_type": "code",
        "outputId": "2a90639e-d286-4143-b06f-b3ee9582c4f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "path = \"/content/drive\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)\n",
        "print(os.getcwd())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w2f1xHUMwCJT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Install cloud vision Api"
      ]
    },
    {
      "metadata": {
        "id": "sRlg-4kPk1Wl",
        "colab_type": "code",
        "outputId": "14fd7f7a-c5b9-4e26-b650-ca5e082ca044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!export GOOGLE_APPLICATION_CREDENTIALS=\"My Drive/Colab Notebooks/452 HW/AMLP-1e0549f99771.json\"\n",
        "!gcloud auth activate-service-account --key-file My\\ Drive/Colab\\ Notebooks/452\\ HW/AMLP-1e0549f99771.json\n",
        "!pip install --upgrade -q google-cloud-vision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Activated service account credentials for: [aml-520@prime-prism-232821.iam.gserviceaccount.com]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oIJgeisov5kb",
        "colab_type": "code",
        "outputId": "7a60098d-6381-4f57-ad55-874ece04c0ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"My Drive/Colab Notebooks/452 HW/AMLP-1e0549f99771.json\"\n",
        "\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "\n",
        "# Instantiates a client\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# The name of the image file to annotate\n",
        "file_name = 'My Drive/Colab Notebooks/452 HW/image_flower/hw8_im1.jpg'\n",
        "\n",
        "# Loads the image into memory\n",
        "with io.open(file_name, 'rb') as image_file:\n",
        "    content = image_file.read()\n",
        "\n",
        "image = types.Image(content=content)\n",
        "\n",
        "# Performs label detection on the image file\n",
        "response = client.label_detection(image=image)\n",
        "labels = response.label_annotations\n",
        "\n",
        "print('Labels:')\n",
        "for label in labels:\n",
        "    print(label.description)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:\n",
            "Flower\n",
            "Sunflower\n",
            "Flowering plant\n",
            "Plant\n",
            "sunflower\n",
            "Yellow\n",
            "Field\n",
            "Daisy family\n",
            "Wildflower\n",
            "Petal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Lkm9SOdFHjt",
        "colab_type": "code",
        "outputId": "34864469-6735-41f2-cbf8-0e83693b588e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"My Drive/Colab Notebooks/452 HW/AMLP-1e0549f99771.json\"\n",
        "\n",
        "# Imports the Google Cloud client library\n",
        "from google.cloud import vision\n",
        "from google.cloud.vision import types\n",
        "\n",
        "# Instantiates a client\n",
        "client = vision.ImageAnnotatorClient()\n",
        "\n",
        "# The name of the image file to annotate\n",
        "file_name = 'My Drive/Colab Notebooks/452 HW/image_flower/hw8_im2.jpg'\n",
        "\n",
        "# Loads the image into memory\n",
        "with io.open(file_name, 'rb') as image_file:\n",
        "    content = image_file.read()\n",
        "\n",
        "image = types.Image(content=content)\n",
        "\n",
        "# Performs label detection on the image file\n",
        "response = client.label_detection(image=image)\n",
        "labels = response.label_annotations\n",
        "\n",
        "print('Labels:')\n",
        "for label in labels:\n",
        "    print(label.description)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Labels:\n",
            "Flower\n",
            "Flowering plant\n",
            "Oxeye daisy\n",
            "Petal\n",
            "Daisy\n",
            "chamomile\n",
            "Plant\n",
            "Marguerite daisy\n",
            "camomile\n",
            "mayweed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YtUE2hVeIr3H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Make prediciton with AutoML model"
      ]
    },
    {
      "metadata": {
        "id": "ku2GBKcKHWPY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#!pip install --upgrade google-cloud-automl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WS2a4DtnGQHN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "from google.cloud import automl_v1beta1\n",
        "from google.cloud.automl_v1beta1.proto import service_pb2\n",
        "\n",
        "\n",
        "def get_prediction(content, project_id, model_id):\n",
        "  prediction_client = automl_v1beta1.PredictionServiceClient()\n",
        "\n",
        "  name = 'projects/{}/locations/us-central1/models/{}'.format(project_id, model_id)\n",
        "  payload = {'image': {'image_bytes': content }}\n",
        "  params = {}\n",
        "  request = prediction_client.predict(name, payload, params)\n",
        "  return request  # waits till request is returned\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9-celw-8GVFO",
        "colab_type": "code",
        "outputId": "4a6420de-a06e-45e4-a205-32d66382195f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = \"My Drive/Colab Notebooks/452 HW/image_flower/hw8_im2.jpg\"\n",
        "with open(file_path, 'rb') as ff:\n",
        "  content = ff.read()\n",
        "\n",
        "print(get_prediction(content, \"prime-prism-232821\",  \"ICN6493707863227294431\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "payload {\n",
            "  classification {\n",
            "    score: 0.9999916553497314\n",
            "  }\n",
            "  display_name: \"daisy\"\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uZGCS8S-IHC6",
        "colab_type": "code",
        "outputId": "2698f604-e2f6-4450-c7cc-fd360dfcaad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "file_path = \"My Drive/Colab Notebooks/452 HW/image_flower/hw8_im1.jpg\"\n",
        "with open(file_path, 'rb') as ff:\n",
        "  content = ff.read()\n",
        "\n",
        "print(get_prediction(content, \"prime-prism-232821\",  \"ICN6493707863227294431\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "payload {\n",
            "  classification {\n",
            "    score: 0.9999648332595825\n",
            "  }\n",
            "  display_name: \"sunflowers\"\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tBbAdZspTRGW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n"
      ]
    },
    {
      "metadata": {
        "id": "PjOc_DzTTU8v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* AutoML wraps up the model building process for image analysis, and provides customizes model which has taget output specified; while Vision API provides a more general image analysis tool to recognize picture content as well as making the classficaiton.\n",
        "\n",
        "*\tSince Vision API is the outer layer of AutoML, Vision API is not as flexible as AutoML when a customized model is needed. And AutoML provides customized options to enable users who do not have much machine learning background to train their own models. \n",
        "\n",
        "* As for the returned results, AutoML can return a quite precise predicted target that specified before; but Vision API will return various labels it identified, which allows a wider range of follow-up analysis with those labels.\n",
        "\n",
        "*  Overall, AutoML is more flexible on image analysis when the task has some specified requirements; while Vision API is a powerful image analytics tool for broader application.\n",
        "\n",
        "\n"
      ]
    }
  ]
}